group_by(method) %>%
summarise_all(mean)
result %>%
filter(method!="cca_rrr", (( method=="ecca") & (fold %in% c(2,4))) == FALSE) %>%
group_by(method) %>%
summarise(mean_pred = mean(pred_acc),
sd_pred = sd(pred_acc),
median_pred = medan(pred_acc))
result %>%
filter(method!="cca_rrr", (( method=="ecca") & (fold %in% c(2,4))) == FALSE) %>%
group_by(method) %>%
summarise(mean_pred = mean(pred_acc),
sd_pred = sd(pred_acc),
median_pred = median(pred_acc))
result %>%
filter(method!="cca_rrr", (( method=="ecca") & (fold %in% c(2,4))) == FALSE) %>%
group_by(method) %>%
summarise(mean_pred = mean(pred_acc),
sd_pred = sd(pred_acc),
median_pred = median(pred_acc)) %>%
arrange(desc(mean_pred))
# Load a single object from an .rds file
setwd("~/Documents/llm_example/")
dir_in   <- "connectome_ew"               # <- adjust if you moved the folder
pattern  <- "^cca_.*\\.rds$"              # only the files you care about
files <- list.files(dir_in, pattern = pattern, full.names = TRUE)
result <- map_dfr(files, function(f) {
## ---- 1.  Parse the file name ------------------------------------------------
##        "cca_METHOD_rank_R_seed_SEED_max_docMAXDOC_qMAXWORDS.rds"
bits <- str_match(
basename(f),
"^cca_neuro_(.*?)_rank_(.*?)_fold_(.*?)\\.rds$"
)
method   <- bits[2]
rank     <- as.integer(bits[3])
fold     <- as.integer(bits[4])
## ---- 2.  Load the .rds (saved with `save()`, so use `load()`) ---------------
e <- new.env(parent = emptyenv())
load(f, envir = e)          # makes fit, timing, correlations, …
print(e$pred_acc)
print(e$fit$lambda)
## objects were lists keyed by method, so pull the right slice
pred_acc      <- e$pred_acc[[method]]
cor_mat       <- diag(e$correlations[[method]])
identity_mat  <- e$identity[[method]]
elapsed       <- unname(e$timing["elapsed"])
accuracy_lda = e$accuracy_lda[[method]]
accuracy_kmean = e$accuracy_kmeans[[method]]
## you may want a single scalar for correlation / identity ‒ adapt as needed
tibble(
file       = basename(f),
method, rank, fold,
pred_acc   = pred_acc,
accuracy_lda = accuracy_lda,
accuracy_kmean= accuracy_kmean,
correlation= mean(cor_mat),        # or diag(cor_mat) if you need each dim
identity   = mean(identity_mat),   # idem
elapsed_s  = elapsed
)
})
result %>%
group_by(method) %>%
summarise(mean_pred = mean(pred_acc),
sd_pred = sd(pred_acc),
median_pred = median(pred_acc)) %>%
arrange(desc(mean_pred))
result <- map_dfr(files, function(f) {
## ---- 1.  Parse the file name ------------------------------------------------
##        "cca_METHOD_rank_R_seed_SEED_max_docMAXDOC_qMAXWORDS.rds"
bits <- str_match(
basename(f),
"^cca_neuro_(.*?)_rank_(.*?)_fold_(.*?)\\.rds$"
)
method   <- bits[2]
rank     <- as.integer(bits[3])
fold     <- as.integer(bits[4])
## ---- 2.  Load the .rds (saved with `save()`, so use `load()`) ---------------
e <- new.env(parent = emptyenv())
load(f, envir = e)          # makes fit, timing, correlations, …
print(e$pred_acc)
print(e$fit$lambda)
## objects were lists keyed by method, so pull the right slice
pred_acc      <- e$pred_acc[[method]]
cor_mat       <- diag(e$correlations[[method]])
identity_mat  <- e$identity[[method]]
elapsed       <- unname(e$timing["elapsed"])
accuracy_lda = e$accuracy_lda[[method]]
accuracy_kmean = e$accuracy_kmeans[[method]]
## you may want a single scalar for correlation / identity ‒ adapt as needed
tibble(
file       = basename(f),
method, rank, fold,
pred_acc   = pred_acc,
accuracy_lda = accuracy_lda,
accuracy_kmean= accuracy_kmean,
correlation= mean(cor_mat),        # or diag(cor_mat) if you need each dim
identity   = mean(identity_mat),   # idem
elapsed_s  = elapsed
)
})
dir_in   <- "connectome_new"               # <- adjust if you moved the folder
pattern  <- "^cca_.*\\.rds$"              # only the files you care about
files <- list.files(dir_in, pattern = pattern, full.names = TRUE)
result <- map_dfr(files, function(f) {
## ---- 1.  Parse the file name ------------------------------------------------
##        "cca_METHOD_rank_R_seed_SEED_max_docMAXDOC_qMAXWORDS.rds"
bits <- str_match(
basename(f),
"^cca_neuro_(.*?)_rank_(.*?)_fold_(.*?)\\.rds$"
)
method   <- bits[2]
rank     <- as.integer(bits[3])
fold     <- as.integer(bits[4])
## ---- 2.  Load the .rds (saved with `save()`, so use `load()`) ---------------
e <- new.env(parent = emptyenv())
load(f, envir = e)          # makes fit, timing, correlations, …
print(e$pred_acc)
print(e$fit$lambda)
## objects were lists keyed by method, so pull the right slice
pred_acc      <- e$pred_acc[[method]]
cor_mat       <- diag(e$correlations[[method]])
identity_mat  <- e$identity[[method]]
elapsed       <- unname(e$timing["elapsed"])
accuracy_lda = e$accuracy_lda[[method]]
accuracy_kmean = e$accuracy_kmeans[[method]]
## you may want a single scalar for correlation / identity ‒ adapt as needed
tibble(
file       = basename(f),
method, rank, fold,
pred_acc   = pred_acc,
accuracy_lda = accuracy_lda,
accuracy_kmean= accuracy_kmean,
correlation= mean(cor_mat),        # or diag(cor_mat) if you need each dim
identity   = mean(identity_mat),   # idem
elapsed_s  = elapsed
)
})
result %>%
group_by(method) %>%
summarise(mean_pred = mean(pred_acc),
sd_pred = sd(pred_acc),
median_pred = median(pred_acc)) %>%
arrange(desc(mean_pred))
ggplot(result) +
geom_boxplot(aes(x=method, y = accuracy_lda)) +
scale_y_log10() +
theme_bw()
ggplot(result) +
geom_boxplot(aes(x=method, y = accuracy_kmean)) +
scale_y_log10() +
theme_bw()
ggplot(result %>% filter(method!="cca_rrr")) +
geom_boxplot(aes(x=method, y = pred_acc)) +
#scale_y_log10() +
theme_bw()
library(ccar3)
library(tidyverse)
# Load a single object from an .rds file
setwd("~/Documents/llm_example/")
dir_in   <- "connectome_new"               # <- adjust if you moved the folder
pattern  <- "^cca_.*\\.rds$"              # only the files you care about
files <- list.files(dir_in, pattern = pattern, full.names = TRUE)
result <- map_dfr(files, function(f) {
## ---- 1.  Parse the file name ------------------------------------------------
##        "cca_METHOD_rank_R_seed_SEED_max_docMAXDOC_qMAXWORDS.rds"
bits <- str_match(
basename(f),
"^cca_neuro_(.*?)_rank_(.*?)_fold_(.*?)\\.rds$"
)
method   <- bits[2]
rank     <- as.integer(bits[3])
fold     <- as.integer(bits[4])
## ---- 2.  Load the .rds (saved with `save()`, so use `load()`) ---------------
e <- new.env(parent = emptyenv())
load(f, envir = e)          # makes fit, timing, correlations, …
print(e$pred_acc)
print(e$fit$lambda)
## objects were lists keyed by method, so pull the right slice
pred_acc      <- e$pred_acc[[method]]
cor_mat       <- diag(e$correlations[[method]])
identity_mat  <- e$identity[[method]]
elapsed       <- unname(e$timing["elapsed"])
accuracy_lda = e$accuracy_lda[[method]]
accuracy_kmean = e$accuracy_kmeans[[method]]
## you may want a single scalar for correlation / identity ‒ adapt as needed
tibble(
file       = basename(f),
method, rank, fold,
pred_acc   = pred_acc,
accuracy_lda = accuracy_lda,
accuracy_kmean= accuracy_kmean,
correlation= mean(cor_mat),        # or diag(cor_mat) if you need each dim
identity   = mean(identity_mat),   # idem
elapsed_s  = elapsed
)
})
result %>%
group_by(method) %>%
summarise(mean_pred = mean(pred_acc),
sd_pred = sd(pred_acc),
median_pred = median(pred_acc)) %>%
arrange(desc(mean_pred))
result %>%
filter(method!="cca_rrr", (( method=="ecca") & (fold %in% c(2,4))) == FALSE) %>%
group_by(method) %>%
summarise(mean_pred = mean(pred_acc),
sd_pred = sd(pred_acc),
median_pred = median(pred_acc)) %>%
arrange(desc(mean_pred))
result %>%
filter(method!="cca_rrr", (( method=="ecca") & (fold %in% c(2,4))) == FALSE) %>%
group_by(method) %>%
summarise(mean_pred = mean(pred_acc),
sd_pred = sd(pred_acc),
median_pred = median(pred_acc)) %>%
arrange(desc(mean_pred))
remove.packages("ccar3")
library(devtools)
document()  # regenerate NAMESPACE and documentation
setwd("~/Documents/ccar3/")
ibrary(devtools)
library(devtools)
document()  # regenerate NAMESPACE and documentation
install()   # reinstall cleanly
library(ccar3)
library(tidyverse)
library(argparse)
data <- readRDS("~/Downloads/XYg_vineland_new2.rds")
dim(data$Y)
X = scale(data$X, center = T, scale=T)[,1:50]
Y = scale(data$Y, center = T, scale=T)
groups = data$group
labels = data$diagnosis
parser <- ArgumentParser(
description = "Train CCA model")
SEED = 1234
set.seed(SEED)
###### create folds
folds = caret::createFolds(1:nrow(X), k = 5)
fold=1
r = 3
##### Run CCA benchmarks
methods <- c(args$method)
methods <- c('ecca')
results <- vector("list", length(methods))
timings <- vector("list", length(methods))
pred_acc <- vector("list", length(methods))
correlations <- vector("list", length(methods))
identity <- vector("list", length(methods))
accuracy_kmeans <- vector("list", length(methods))
accuracy_lda <- vector("list", length(methods))
names(results) <- names(timings)<- names(correlations)<- names(pred_acc)<- names(identity) <- names(accuracy_lda)<- names(accuracy_kmeans)<- methods
X_train = X[-folds[[fold]],]
X_test = X[folds[[fold]],]
Y_train =  Y[-folds[[fold]],]
Y_test = Y[folds[[fold]],]
labels_train = labels[-folds[[fold]]]
labels_test = labels[folds[[fold]]]
print('dim X')
print(dim(X))
print('dim Y')
print(dim(Y))
i = 1
list_groups = list()
for (g in unique(groups)){
list_groups[[i]] = which(groups == g)
i = i + 1
}
for (method in methods) {
filename <- sprintf(
"/Users/clairedonnat/Documents/llm_example/CCA_results/cca_neuro_%s_rank_%s_fold_%s.rds",
method, r, fold
)
## 2. Check sd before scaling
sd_x <- apply(X_train, 2, sd)
sd_y <- apply(Y_train, 2, sd)
zero_x <- which(sd_x == 0 | is.na(sd_x))
zero_y <- which(sd_y == 0 | is.na(sd_y))
## ---- Fit model, skipping on error ------------------------------------
start_time <- proc.time()           # manual timer lets us skip timing() on error
fit <- tryCatch(
if ((method %in% c("ecca", "ecca_group", "cca_group_rrr", "cca_rrr" )) == FALSE){
sparse_CCA_benchmarks(
X_train,
Y_train,
rank      = r,
lambdax   = 10 ^ seq(-3,  0, length = 10),
lambday   = 10 ^ seq(-3,  0, length = 10),
method.type = method,
kfolds = 5,
standardize = TRUE
)
}else{
if (method == "ecca"){
ecca.cv(scale(X_train, center = TRUE, scale = TRUE),
scale(Y_train, center = TRUE, scale = TRUE),
lambdas = 10 ^ seq(-4,  0, length = 20))
}
if (method == "ecca_groups"){
ecca.cv(scale(X_train, center = TRUE, scale = TRUE),
scale(Y_train, center = TRUE, scale = TRUE),
groups = groups,
lambdas = 10 ^ seq(-4,  0, length = 20))
}else{
cca_rrr_cv(scale(X_train, center = TRUE, scale = TRUE),
scale(Y_train, center = TRUE, scale = TRUE),
lambdas = 10 ^ seq(-4,  0, length = 20), parallelize = F)
}
}
,
error = function(e) {
message(sprintf("❌  %s failed: %s – skipping.", method, e$message))
return(NULL)                    # fit will be NULL → we’ll hit `next`
}
)
if (is.null(fit)) next              # skip to the next method on error
timing <- proc.time() - start_time
## ---- Evaluate the results
dim(X_test)
normsU = colSums(fit$U^2)
normsV = colSums(fit$V^2)
idxu = which(normsU == 0)
idxv = which(normsV == 0)
idx_remove = unique(idxu, idxv)
fit$U = fit$U[,-idx_remove]
fit$V = fit$V[,-idx_remove]
pred_acc[[method]]  = mean(apply((scale(X_test, center = TRUE, scale = TRUE)%*% fit$U  -scale(Y_test, center = TRUE, scale = TRUE)%*% fit$V  )^2, 1, sum))
correlations[[method]] = diag(cor(scale(X_test, center = TRUE, scale = TRUE)%*% fit$U , scale(Y_test, center = TRUE, scale = TRUE)%*% fit$V ))
identity[[method]]  = t(scale(X_test, center = TRUE, scale = TRUE)%*% fit$U) %*% scale(Y_test, center = TRUE, scale = TRUE)%*% fit$V/ nrow(Y_test)
# Cluster outputs based on diagnostic
test_cluster = kmeans(1/sqrt(nrow(X_test)) * scale(X_test, center = TRUE, scale = TRUE)%*% fit$U, 2) #)
pred = test_cluster$cluster
truth <- factor(labels_test, levels = c("Autism", "Control"))   # ensure order
eval_kmeans = eval_clustering(pred, truth)
print(idx_remove)
if (length(idx_remove)>0){
fit$U = fit$U[,-idx_remove]
fit$V = fit$V[,-idx_remove]
}
pred_acc[[method]]  = mean(apply((X_test%*% fit$U  -Y_test%*% fit$V  )^2, 1, sum))
correlations[[method]] = diag(cor(X_test%*% fit$U , Y_test%*% fit$V ))
identity[[method]]  = t(X_test%*% fit$U) %*% Y_test%*% fit$V/ nrow(Y_test)
# Cluster outputs based on diagnostic
#test_cluster = kmeans(1/sqrt(nrow(X_test)) * scale(X_test, center = TRUE, scale = TRUE)%*% fit$U, 2) #)
#pred = test_cluster$cluster
#truth <- factor(labels_test, levels = c("Autism", "Control"))   # ensure order
#eval_kmeans = eval_clustering(pred, truth)
eval_kmeans <- tryCatch({
## --- code that might fail ------------------------------------------
test_cluster <- kmeans(
1 / sqrt(nrow(X_test)) *
X_test %*% fit$U,
centers = 2
)
pred  <- test_cluster$cluster
truth <- factor(labels_test, levels = c("Autism", "Control"))
eval_clustering(pred, truth)      # returned if everything succeeds
## -------------------------------------------------------------------
}, error = function(e) {
message("k-means step failed: ", e$message)
NA                              # or any default you prefer
})
#### Now fit a classifier (LDA) to do the same
split_idx <- caret::createFolds(labels_test,   # keeps class balance
k=2)
X_test= X_test
acc_lda = 0
for (k in 1:length(split_idx)){
X_train2 <- X_test[ -split_idx[[k]], , drop = FALSE]
X_test2  <- X_test[split_idx[[k]], , drop = FALSE]
labels_train2 <- labels_test[ -split_idx[[k]]]
labels_test2  <- labels_test[split_idx[[k]]]
lda_fit <- MASS::lda(1/sqrt(nrow(X_train2)) * X_train2%*% fit$U,, grouping = labels_train2)
lda_pred <- predict(lda_fit, 1/sqrt(nrow(X_test2)) * X_test2%*% fit$U)$class   # factor with "Autism"/"Control"
## ------------------------------------------------------------------
## 4.  Evaluate – reuse the clustering wrapper for consistency
##     (eval_clustering handles label permutations, but here pred
##      already matches class names, so mapping is trivial)
## ------------------------------------------------------------------
eval_lda <- eval_clustering(lda_pred, labels_test2)
acc_lda = acc_lda + eval_lda$accuracy/k
}
## ---- Store in memory --------------------------------------------------
results[[method]]  <- fit
timings[[method]]  <- timing
accuracy_lda[[method]]  <- acc_lda
accuracy_kmeans[[method]]  <- eval_kmeans$accuracy
## ---- Persist immediately ---------------------------------------------
save(fit, timing,correlations, pred_acc, identity,
accuracy_lda, accuracy_kmeans,file = filename)
message(sprintf("✅  %s finished (%.2f s elapsed)", method, timing["elapsed"]))
}
###### create folds
folds = caret::createFolds(1:nrow(X), k = 10)
fold = as.integer(args$fold)
r =  as.integer(args$r)
fold=1
r = 3
##### Run CCA benchmarks
methods <- c(args$method)
methods <- c('ecca')
results <- vector("list", length(methods))
timings <- vector("list", length(methods))
pred_acc <- vector("list", length(methods))
correlations <- vector("list", length(methods))
identity <- vector("list", length(methods))
accuracy_kmeans <- vector("list", length(methods))
accuracy_lda <- vector("list", length(methods))
names(results) <- names(timings)<- names(correlations)<- names(pred_acc)<- names(identity) <- names(accuracy_lda)<- names(accuracy_kmeans)<- methods
X_train = X[-folds[[fold]],]
X_test = X[folds[[fold]],]
Y_train =  Y[-folds[[fold]],]
Y_test = Y[folds[[fold]],]
labels_train = labels[-folds[[fold]]]
labels_test = labels[folds[[fold]]]
print('dim X')
print(dim(X))
print('dim Y')
print(dim(Y))
i = 1
list_groups = list()
for (g in unique(groups)){
list_groups[[i]] = which(groups == g)
i = i + 1
}
ecca.cv(scale(X_train, center = TRUE, scale = TRUE),
scale(Y_train, center = TRUE, scale = TRUE),
lambdas = 10 ^ seq(-4,  0, length = 20))
result %>%
group_by(method) %>%
summarise(mean_pred = mean(pred_acc),
sd_pred = sd(pred_acc),
median_pred = median(pred_acc)) %>%
arrange(desc(mean_pred))
result %>%
filter(method!="cca_rrr", (( method=="ecca") & (fold %in% c(2,4))) == FALSE) %>%
group_by(method) %>%
summarise(mean_pred = mean(pred_acc),
sd_pred = sd(pred_acc),
median_pred = median(pred_acc)) %>%
arrange(desc(mean_pred))
library(ccar3)
library(tidyverse)
library(argparse)
data <- readRDS("~/Downloads/XYg_vineland_new2.rds")
dim(data$Y)
S = cov(data$X, data$Y)
D
S
test = svd(S)
plot(test$d
)
S = cov(scale(data$X, center = T, scale=T),  scale(data$Y, center = T, scale=T))
test = svd(S)
plot(test$d
)
remove.packages("ccar3")
quit()
library(devtools)
document()  # regenerate NAMESPACE and documentation
install()   # reinstall cleanly
quit()
remove.packages("ccar3")
quit()
quit()
devtools::document()
quit()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::check_win_devel()
devtools::check_win_release()
devtools::check_rhub(platforms = c("debian-clang-devel", "debian-gcc-devel"))
library(rhub)
# see available platforms
platforms()
?rhubv2
rhub_setup()
q
quit()
?rhubv2
library(rhub)
?rhubv2
rhub_setup()
quit()
rhub_setup()
rhaub::rhub_setup()
rhub::rhub_setup()
rhub::rhub_check()
rhub::rhub_check()
rhub::rhub_check()
quit()
rhub::rhub_check()
rhub::rhub_check()
rhub::rhub_check()
rhub::rhub_check()
devtools::check()
quit()
rhub::rhub_check()
rhub::rhub_check()
rhub::rhub_check()
devtools::document()
devtools::check()
devtools::check()
devtools::check()
rhub::rhub_check()
quit()
devtools::document()
quit()
devtools::document()
quit()
